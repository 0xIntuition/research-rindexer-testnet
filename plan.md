# Refactor Plan: Materialized Views → Trigger-Based Tables

## Overview

Replace all 9 materialized views with regular tables that update in real-time via PostgreSQL triggers. This eliminates manual refresh operations and provides immediate data availability as blockchain events arrive.

**Key Requirements:**
- Real-time updates (no manual refresh)
- Full feature parity with current views
- Database-only solution (no rindexer/app changes)
- Handle non-sequential event arrival (seconds-minutes out-of-order)
- Replace existing migrations (clean slate, no data migration)

---

## Current State Analysis

### Materialized Views (9 total)

**Level 0 - Base Views:**
1. **atom** - 1:1 transform from `atom_created` events
2. **triple** - 1:1 transform from `triple_created` events (uses Python UDF for counter-triple ID)
3. **position** - Complex aggregation from `deposited` + `redeemed` events

**Level 1:**
4. **vault** - Depends on `position` + `share_price_changed` events
5. **triple_vault** - Depends on `triple` + `vault`

**Level 2:**
6. **term** - Aggregates `vault` by term_id
7. **triple_term** - Aggregates `triple_vault` by term_id

**Level 3 - Analytics:**
8. **predicate_object** - Groups triples by predicate-object pairs
9. **subject_predicate** - Groups triples by subject-predicate pairs

### Current Migrations to Replace

**Keep unchanged:**
- `migrations/rindexer-schema.sql` - Raw event tables (generated by rindexer)
- `migrations/00-indexes.sql` - Indexes on raw event tables
- `migrations/01-crypto.sql` - Python UDF functions (keccak256, calculateCounterTripleId)

**Replace with trigger-based approach:**
- `migrations/02-position.sql` → New trigger-based implementation
- `migrations/03-vault.sql` → New trigger-based implementation
- `migrations/04-term.sql` → New trigger-based implementation
- `migrations/05-atom.sql` → New trigger-based implementation
- `migrations/06-triple.sql` → New trigger-based implementation
- `migrations/07-triple_vault.sql` → New trigger-based implementation
- `migrations/08-triple_term.sql` → New trigger-based implementation
- `migrations/09-predicate-aggregates.sql` → New trigger-based implementation
- `migrations/99-refresh.sql` → DELETE (no longer needed)

---

## Refactor Architecture

### Core Design Principles

1. **Regular Tables Instead of Materialized Views**
   - Standard tables with INSERT/UPDATE/DELETE operations
   - No manual refresh required

2. **Triggers on Raw Event Tables**
   - `atom_created` → triggers updates to `atom` table
   - `triple_created` → triggers updates to `triple` table
   - `deposited` → triggers updates to `position` table
   - `redeemed` → triggers updates to `position` table
   - `share_price_changed` → triggers updates to `vault` table

3. **Cascading Triggers Between Tables**
   - Changes to `position` → cascade to `vault`
   - Changes to `vault` → cascade to `term`
   - Changes to `triple` + `vault` → cascade to `triple_vault`
   - Changes to `triple_vault` → cascade to `triple_term`
   - Changes to upper-level tables → cascade to analytics views

4. **Out-of-Order Event Handling**
   - Add tracking columns to all tables: `last_updated_block`, `last_updated_log_index`
   - Use conditional UPSERT: only update if new event is "later" than existing
   - Comparison logic: `(block_number, log_index)` tuple ordering

### Out-of-Order Event Strategy

**Problem:** Events can arrive non-sequentially (e.g., block 100 arrives before block 99)

**Solution:** Conditional updates based on event ordering

```sql
-- Pattern for all triggers
INSERT INTO target_table (...)
VALUES (...)
ON CONFLICT (primary_key) DO UPDATE SET
  column = EXCLUDED.column,
  last_updated_block = EXCLUDED.block_number,
  last_updated_log_index = EXCLUDED.log_index
WHERE
  -- Only update if new event is "later" than existing
  (EXCLUDED.block_number > target_table.last_updated_block) OR
  (EXCLUDED.block_number = target_table.last_updated_block AND
   EXCLUDED.log_index > target_table.last_updated_log_index);
```

**Key Points:**
- Events from older blocks are ignored if newer data already exists
- Within same block, log_index determines ordering
- Ensures eventual consistency as late events arrive

---

## Detailed Implementation Strategy

### 1. ATOM Table (Level 0) - SIMPLE

**Source:** `atom_created` events (1:1 transform)

**Table Schema:**
```sql
CREATE TABLE atom (
  id bytea PRIMARY KEY,
  atom_id text UNIQUE NOT NULL,  -- hex encoded
  label text,
  emoji text,
  data bytea,
  data_hex text,
  creator text,
  wallet text,
  type atom_type DEFAULT 'thing',
  image text,
  resolving_status atom_resolving_status DEFAULT 'pending',
  created_at timestamp with time zone,
  block_number numeric,
  block_hash text,
  tx_hash text,
  -- Tracking columns
  last_updated_block numeric NOT NULL,
  last_updated_log_index text NOT NULL
);
```

**Trigger Logic:**
```sql
CREATE TRIGGER atom_created_insert_trigger
AFTER INSERT ON intuition_multi_vault.atom_created
FOR EACH ROW EXECUTE FUNCTION update_atom();
```

**Function `update_atom()`:**
- Decode UTF-8 label from atom_data using `safe_utf8_decode()`
- Generate hex-encoded IDs
- INSERT on conflict DO UPDATE with block/log_index comparison
- Simple 1:1 mapping

**Complexity:** ⭐ (Very Simple)

---

### 2. TRIPLE Table (Level 0) - MODERATE

**Source:** `triple_created` events (1:1 transform)

**Table Schema:**
```sql
CREATE TABLE triple (
  id bytea PRIMARY KEY,
  triple_id text UNIQUE NOT NULL,  -- hex encoded
  subject_id bytea,
  predicate_id bytea,
  object_id bytea,
  counter_triple_id bytea,  -- calculated via Python UDF
  counter_triple_id_hex text,
  creator text,
  created_at timestamp with time zone,
  block_number numeric,
  block_hash text,
  tx_hash text,
  -- Tracking columns
  last_updated_block numeric NOT NULL,
  last_updated_log_index text NOT NULL
);
```

**Trigger Logic:**
```sql
CREATE TRIGGER triple_created_insert_trigger
AFTER INSERT ON intuition_multi_vault.triple_created
FOR EACH ROW EXECUTE FUNCTION update_triple();
```

**Function `update_triple()`:**
- Call Python UDF: `calculateCounterTripleId(NEW.term_id)`
- Generate hex-encoded IDs
- INSERT on conflict DO UPDATE with block/log_index comparison

**Complexity:** ⭐⭐ (Moderate - Python UDF dependency)

---

### 3. POSITION Table (Level 0) - VERY COMPLEX

**Source:** `deposited` + `redeemed` events (aggregation + latest state)

**Challenge:** Must track:
- Latest shares (from most recent deposit OR redeem)
- Total deposited assets (SUM of all historical deposits)
- Total redeemed assets (SUM of all historical redemptions)
- Which event type was most recent (deposit vs redeem)

**Table Schema:**
```sql
CREATE TABLE position (
  vault_id text PRIMARY KEY,  -- receiver || term_id || curve_id
  receiver text NOT NULL,
  term_id bytea NOT NULL,
  term_id_hex text NOT NULL,
  curve_id numeric NOT NULL,

  -- Current state (from latest event)
  shares numeric,

  -- Historical aggregates
  total_deposited numeric,
  total_redeemed numeric,

  -- Latest event metadata
  last_event_type text,  -- 'deposit' or 'redeem'
  last_event_block numeric,
  last_event_log_index text,

  -- Timestamps
  created_at timestamp with time zone,
  updated_at timestamp with time zone,

  -- Tracking columns
  last_updated_block numeric NOT NULL,
  last_updated_log_index text NOT NULL,

  UNIQUE (receiver, term_id, curve_id)
);
```

**Trigger Logic:**
```sql
-- Two triggers: one for deposits, one for redeems
CREATE TRIGGER deposited_insert_trigger
AFTER INSERT ON intuition_multi_vault.deposited
FOR EACH ROW EXECUTE FUNCTION update_position_deposit();

CREATE TRIGGER redeemed_insert_trigger
AFTER INSERT ON intuition_multi_vault.redeemed
FOR EACH ROW EXECUTE FUNCTION update_position_redeem();
```

**Function `update_position_deposit()`:**
1. Calculate vault_id: `NEW.receiver || '0x' || encode(NEW.term_id, 'hex') || NEW.curve_id`
2. Check if position exists
3. If not exists:
   - INSERT new position with shares, total_deposited
   - Set last_event_type = 'deposit'
4. If exists:
   - Check if new event is later than last_event
   - If later OR (same block and later log_index):
     - UPDATE shares to new deposit shares
     - ADD to total_deposited
     - Update last_event_type, block, log_index
   - If earlier event (out-of-order):
     - Only UPDATE total_deposited (accumulate)
     - DO NOT update shares or last_event metadata

**Function `update_position_redeem()`:**
1. Calculate vault_id (same as deposit)
2. Check if position exists
3. If not exists:
   - INSERT new position with shares=0, total_redeemed
   - Set last_event_type = 'redeem'
4. If exists:
   - Check if new event is later than last_event
   - If later:
     - UPDATE shares to new redeem shares
     - ADD to total_redeemed
     - Update last_event_type, block, log_index
   - If earlier event (out-of-order):
     - Only UPDATE total_redeemed (accumulate)
     - DO NOT update shares or last_event metadata

**Key Logic:**
- **Latest shares:** Only updated if event is chronologically later
- **Historical totals:** Always accumulated regardless of order
- **Comparison:** Use (block_number, log_index) tuple to determine "later"

**Complexity:** ⭐⭐⭐⭐⭐ (Very Complex)

---

### 4. VAULT Table (Level 1) - COMPLEX

**Source:** `share_price_changed` events + aggregation from `position` table

**Dependencies:** `position` table (for position_count)

**Table Schema:**
```sql
CREATE TABLE vault (
  vault_id text PRIMARY KEY,  -- term_id_hex || curve_id
  term_id bytea NOT NULL,
  term_id_hex text NOT NULL,
  curve_id numeric NOT NULL,
  vault_type vault_type,

  -- Latest share price data
  current_share_price numeric,
  total_assets numeric,
  total_shares numeric,

  -- Aggregated data from positions
  position_count bigint DEFAULT 0,

  -- Calculated
  market_cap numeric,  -- (total_shares * current_share_price) / 1e18

  -- Timestamps
  created_at timestamp with time zone,
  updated_at timestamp with time zone,

  -- Tracking columns
  last_updated_block numeric NOT NULL,
  last_updated_log_index text NOT NULL,

  UNIQUE (term_id, curve_id)
);
```

**Trigger Logic:**
```sql
-- Primary trigger: share_price_changed events
CREATE TRIGGER share_price_changed_insert_trigger
AFTER INSERT ON intuition_multi_vault.share_price_changed
FOR EACH ROW EXECUTE FUNCTION update_vault_price();

-- Secondary trigger: position changes
CREATE TRIGGER position_change_trigger
AFTER INSERT OR UPDATE ON position
FOR EACH ROW EXECUTE FUNCTION update_vault_position_count();
```

**Function `update_vault_price()`:**
1. Calculate vault_id from term_id and curve_id
2. Calculate market_cap: `(NEW.total_shares * NEW.share_price) / 1e18`
3. Map vault_type enum: 0→Atom, 1→Triple, 2→CounterTriple
4. INSERT on conflict DO UPDATE:
   - Update share price, total_assets, total_shares, market_cap
   - Only if new event is later than last_updated

**Function `update_vault_position_count()`:**
1. Recalculate position_count for affected vault:
   ```sql
   SELECT COUNT(*) FROM position
   WHERE term_id = NEW.term_id
     AND curve_id = NEW.curve_id
     AND shares > 0
   ```
2. UPDATE vault SET position_count = calculated_count
3. No block/log_index comparison (always recalculate from current state)

**Complexity:** ⭐⭐⭐⭐ (Complex - depends on position table)

---

### 5. TERM Table (Level 2) - MODERATE

**Source:** Aggregation of `vault` table grouped by term_id

**Dependencies:** `vault` table

**Table Schema:**
```sql
CREATE TABLE term (
  term_id bytea PRIMARY KEY,
  term_id_hex text UNIQUE NOT NULL,
  term_type term_type,
  atom_id bytea,
  triple_id bytea,

  -- Aggregated from vaults
  total_assets numeric,
  market_cap numeric,
  position_count bigint,

  -- Timestamps
  created_at timestamp with time zone,
  updated_at timestamp with time zone
);
```

**Trigger Logic:**
```sql
CREATE TRIGGER vault_change_trigger
AFTER INSERT OR UPDATE ON vault
FOR EACH ROW EXECUTE FUNCTION update_term();
```

**Function `update_term()`:**
1. Aggregate all vaults for the affected term_id:
   ```sql
   SELECT
     term_id,
     vault_type,  -- determines term_type
     SUM(total_assets) as total_assets,
     SUM(market_cap) as market_cap,
     SUM(position_count) as position_count,
     MIN(created_at) as created_at,
     MAX(updated_at) as updated_at
   FROM vault
   WHERE term_id = NEW.term_id
   GROUP BY term_id, vault_type
   ```
2. INSERT on conflict DO UPDATE with aggregated values
3. Set atom_id or triple_id based on term_type

**Complexity:** ⭐⭐⭐ (Moderate - GROUP BY aggregation)

---

### 6. TRIPLE_VAULT Table (Level 1) - COMPLEX

**Source:** Join `triple` + `vault` tables (both pro and counter vaults)

**Dependencies:** `triple` table, `vault` table

**Table Schema:**
```sql
CREATE TABLE triple_vault (
  vault_id text PRIMARY KEY,  -- term_id_hex || curve_id
  term_id bytea NOT NULL,
  term_id_hex text NOT NULL,
  counter_term_id bytea,
  counter_term_id_hex text,
  curve_id numeric NOT NULL,

  -- Triple metadata
  subject_id bytea,
  predicate_id bytea,
  object_id bytea,
  triple_creator text,
  triple_block_number numeric,

  -- Vault data (aggregated from pro + counter vaults)
  vault_type vault_type,
  total_shares numeric,
  total_assets numeric,
  position_count bigint,
  market_cap numeric,

  -- Timestamps
  created_at timestamp with time zone,
  updated_at timestamp with time zone,

  UNIQUE (term_id, curve_id)
);
```

**Trigger Logic:**
```sql
-- Trigger from triple table
CREATE TRIGGER triple_change_trigger
AFTER INSERT OR UPDATE ON triple
FOR EACH ROW EXECUTE FUNCTION update_triple_vault_from_triple();

-- Trigger from vault table
CREATE TRIGGER vault_change_trigger_for_triple
AFTER INSERT OR UPDATE ON vault
FOR EACH ROW EXECUTE FUNCTION update_triple_vault_from_vault();
```

**Function `update_triple_vault_from_triple()`:**
1. For the new/updated triple, find all associated vaults:
   - Vaults where vault.term_id = triple.id (pro vault)
   - Vaults where vault.term_id = triple.counter_triple_id (counter vault)
2. For each vault, aggregate pro + counter data:
   ```sql
   SELECT
     term_id,
     curve_id,
     SUM(total_shares) as total_shares,
     SUM(total_assets) as total_assets,
     SUM(position_count) as position_count,
     SUM(market_cap) as market_cap
   FROM vault
   WHERE term_id = triple.id OR term_id = triple.counter_triple_id
   GROUP BY term_id, curve_id
   ```
3. INSERT on conflict DO UPDATE with aggregated values

**Function `update_triple_vault_from_vault()`:**
1. Find which triple(s) this vault belongs to:
   - Check if vault.term_id matches any triple.id
   - Check if vault.term_id matches any triple.counter_triple_id
2. For each matching triple, recalculate triple_vault (same aggregation as above)

**Complexity:** ⭐⭐⭐⭐ (Complex - UNION ALL logic, multiple dependencies)

---

### 7. TRIPLE_TERM Table (Level 2) - MODERATE

**Source:** Aggregation of `triple_vault` table grouped by term_id

**Dependencies:** `triple_vault` table

**Table Schema:**
```sql
CREATE TABLE triple_term (
  term_id bytea PRIMARY KEY,
  term_id_hex text UNIQUE NOT NULL,
  counter_term_id bytea,
  counter_term_id_hex text,

  subject_id bytea,
  predicate_id bytea,
  object_id bytea,

  -- Aggregated from triple_vaults
  total_assets numeric,
  total_market_cap numeric,
  total_position_count bigint,

  -- Timestamps
  created_at timestamp with time zone,
  updated_at timestamp with time zone
);
```

**Trigger Logic:**
```sql
CREATE TRIGGER triple_vault_change_trigger
AFTER INSERT OR UPDATE ON triple_vault
FOR EACH ROW EXECUTE FUNCTION update_triple_term();
```

**Function `update_triple_term()`:**
1. Aggregate all triple_vaults for the affected term_id:
   ```sql
   SELECT
     term_id,
     counter_term_id,
     subject_id, predicate_id, object_id,
     SUM(total_assets) as total_assets,
     SUM(market_cap) as total_market_cap,
     SUM(position_count) as total_position_count,
     MIN(created_at) as created_at,
     MAX(updated_at) as updated_at
   FROM triple_vault
   WHERE term_id = NEW.term_id
   GROUP BY term_id, counter_term_id, subject_id, predicate_id, object_id
   ```
2. INSERT on conflict DO UPDATE with aggregated values

**Complexity:** ⭐⭐⭐ (Moderate - GROUP BY aggregation)

---

### 8. PREDICATE_OBJECT Table (Level 3) - MODERATE

**Source:** Aggregation of triples grouped by predicate-object pairs

**Dependencies:** `triple` table, `triple_term` table (LEFT JOIN)

**Table Schema:**
```sql
CREATE TABLE predicate_object (
  id text PRIMARY KEY,  -- predicate_id_hex || object_id_hex
  predicate_id bytea NOT NULL,
  predicate_id_hex text NOT NULL,
  object_id bytea NOT NULL,
  object_id_hex text NOT NULL,

  -- Aggregated metrics
  triple_count bigint,
  total_position_count bigint,
  total_market_cap numeric,

  -- Timestamps
  updated_at timestamp with time zone
);
```

**Trigger Logic:**
```sql
-- Trigger from triple table
CREATE TRIGGER triple_change_trigger_for_predicate_object
AFTER INSERT OR UPDATE OR DELETE ON triple
FOR EACH ROW EXECUTE FUNCTION update_predicate_object();

-- Trigger from triple_term table
CREATE TRIGGER triple_term_change_trigger_for_predicate_object
AFTER INSERT OR UPDATE ON triple_term
FOR EACH ROW EXECUTE FUNCTION update_predicate_object_from_triple_term();
```

**Function `update_predicate_object()`:**
1. For affected predicate_id + object_id combination:
   ```sql
   SELECT
     predicate_id,
     object_id,
     COUNT(DISTINCT term_id) as triple_count,
     COALESCE(SUM(tt.total_position_count), 0) as total_position_count,
     COALESCE(SUM(tt.total_market_cap), 0) as total_market_cap
   FROM triple t
   LEFT JOIN triple_term tt ON t.id = tt.term_id
   WHERE predicate_id = NEW.predicate_id
     AND object_id = NEW.object_id
   GROUP BY predicate_id, object_id
   ```
2. INSERT on conflict DO UPDATE with aggregated values

**Complexity:** ⭐⭐⭐ (Moderate - GROUP BY with LEFT JOIN)

---

### 9. SUBJECT_PREDICATE Table (Level 3) - MODERATE

**Source:** Aggregation of triples grouped by subject-predicate pairs

**Dependencies:** `triple` table, `triple_term` table (LEFT JOIN)

**Table Schema:**
```sql
CREATE TABLE subject_predicate (
  id text PRIMARY KEY,  -- subject_id_hex || predicate_id_hex
  subject_id bytea NOT NULL,
  subject_id_hex text NOT NULL,
  predicate_id bytea NOT NULL,
  predicate_id_hex text NOT NULL,

  -- Aggregated metrics
  triple_count bigint,
  total_position_count bigint,
  total_market_cap numeric,

  -- Timestamps
  updated_at timestamp with time zone
);
```

**Trigger Logic:**
```sql
-- Trigger from triple table
CREATE TRIGGER triple_change_trigger_for_subject_predicate
AFTER INSERT OR UPDATE OR DELETE ON triple
FOR EACH ROW EXECUTE FUNCTION update_subject_predicate();

-- Trigger from triple_term table
CREATE TRIGGER triple_term_change_trigger_for_subject_predicate
AFTER INSERT OR UPDATE ON triple_term
FOR EACH ROW EXECUTE FUNCTION update_subject_predicate_from_triple_term();
```

**Function `update_subject_predicate()`:**
1. For affected subject_id + predicate_id combination:
   ```sql
   SELECT
     subject_id,
     predicate_id,
     COUNT(DISTINCT term_id) as triple_count,
     COALESCE(SUM(tt.total_position_count), 0) as total_position_count,
     COALESCE(SUM(tt.total_market_cap), 0) as total_market_cap
   FROM triple t
   LEFT JOIN triple_term tt ON t.id = tt.term_id
   WHERE subject_id = NEW.subject_id
     AND predicate_id = NEW.predicate_id
   GROUP BY subject_id, predicate_id
   ```
2. INSERT on conflict DO UPDATE with aggregated values

**Complexity:** ⭐⭐⭐ (Moderate - GROUP BY with LEFT JOIN)

---

## Migration File Structure (Replacement Strategy)

### Files to Keep
- `rindexer-schema.sql` - Raw event tables (no changes)
- `00-indexes.sql` - Indexes on raw event tables (no changes)
- `01-crypto.sql` - Python UDF functions (no changes)

### Files to Replace

**New `02-tables.sql`** (replaces 02-06):
- Create all 9 regular tables (atom, triple, position, vault, term, triple_vault, triple_term, predicate_object, subject_predicate)
- Add tracking columns (last_updated_block, last_updated_log_index)
- Create all indexes (including unique indexes for ON CONFLICT)
- Create custom types (vault_type, term_type, atom_type, etc.)

**New `03-trigger-functions.sql`** (replaces 07-09, 99):
- Helper functions for out-of-order event handling
- Level 0 trigger functions (atom, triple, position)
- Level 1 trigger functions (vault, triple_vault)
- Level 2 trigger functions (term, triple_term)
- Level 3 trigger functions (predicate_object, subject_predicate)
- All trigger declarations

**Delete:**
- `99-refresh.sql` - No longer needed (no materialized views)

---

## Performance Considerations

### Trigger Overhead

**Per-Event Cost:**
- Each `deposited` event: 3 triggers (position → vault → term)
- Each `share_price_changed` event: 2 triggers (vault → term)
- Each `atom_created` event: 1 trigger (atom)
- Each `triple_created` event: 4 triggers (triple → triple_vault → triple_term → analytics)

**Worst Case:** A `deposited` event on a triple vault:
1. `update_position_deposit()` - position table
2. `update_vault_position_count()` - vault table
3. `update_term()` - term table
4. `update_triple_vault_from_vault()` - triple_vault table
5. `update_triple_term()` - triple_term table
6. `update_predicate_object()` - predicate_object table
7. `update_subject_predicate()` - subject_predicate table

= **7 trigger executions per single event**

### Optimization Strategies

1. **Conditional Execution**
   - Early exit if event is out-of-order and doesn't affect aggregates
   - Skip unnecessary cascades when data hasn't changed

2. **Efficient Aggregations**
   - Use covering indexes for GROUP BY queries
   - Keep aggregation queries simple (avoid complex CTEs in triggers)

3. **AFTER INSERT Triggers**
   - Use row-level triggers (not statement-level) for precise updates
   - PostgreSQL batches multiple row triggers efficiently

4. **Index Strategy**
   - Maintain all existing indexes from 00-indexes.sql
   - Add indexes on (term_id, curve_id) for vault aggregations
   - Add indexes on (predicate_id, object_id) and (subject_id, predicate_id) for analytics

5. **Connection Pooling**
   - Rindexer should use connection pooling to minimize overhead
   - Consider pgBouncer if INSERT rate is very high

### Lock Contention

**Potential Bottlenecks:**
- Popular vaults (many positions) may have high UPDATE frequency
- term table updates (multiple vaults per term can cause serialization)
- Analytics tables (many triples share same predicate/subject)

**Mitigation:**
- Use `SELECT FOR UPDATE SKIP LOCKED` in high-contention scenarios (not applicable here)
- Consider `DEFERRABLE` constraints if deadlocks occur
- Monitor `pg_stat_activity` and `pg_locks` for contention

### Initial Load Performance

**First Run (from scratch):**
- No initial data to process (fresh start)
- Triggers execute as events arrive from rindexer
- Expected rate: ~1000-5000 events/second (typical rindexer throughput)
- Monitor with: `SELECT COUNT(*) FROM position; SELECT COUNT(*) FROM vault;`

---

## Testing Strategy

### 1. Trigger Logic Validation

**Test Cases:**
- In-order events (block 100, 101, 102...)
- Out-of-order events (block 100, 99, 101)
- Same-block events with different log_index
- Duplicate events (should be idempotent via ON CONFLICT)

**Test Data:**
```sql
-- Insert synthetic events in various orders
INSERT INTO intuition_multi_vault.atom_created (...);
INSERT INTO intuition_multi_vault.deposited (...);
-- Verify resulting tables match expected state
SELECT * FROM atom WHERE ...;
SELECT * FROM position WHERE ...;
```

### 2. Performance Testing

**Metrics to Monitor:**
- INSERT throughput (events/second)
- Trigger execution time (use `EXPLAIN ANALYZE`)
- Table bloat (monitor autovacuum activity)
- Lock wait times (`pg_stat_activity`)

**Benchmark:**
```sql
-- Measure trigger execution time
EXPLAIN ANALYZE
INSERT INTO intuition_multi_vault.deposited (...);
```

### 3. Data Integrity Validation

**Spot Checks:**
- Compare position.shares against raw deposited/redeemed aggregations
- Verify vault.position_count matches COUNT(*) from position table
- Validate term aggregations match SUM() across vaults
- Check triple_vault includes both pro + counter vault data

**Sample Queries:**
```sql
-- Verify position shares
SELECT
  p.vault_id,
  p.shares as trigger_shares,
  (SELECT shares FROM deposited WHERE receiver = p.receiver AND term_id = p.term_id ORDER BY block_number DESC, log_index DESC LIMIT 1) as latest_deposit_shares
FROM position p
WHERE p.shares != (SELECT ...);  -- Should return 0 rows

-- Verify vault position_count
SELECT
  v.vault_id,
  v.position_count as trigger_count,
  (SELECT COUNT(*) FROM position WHERE term_id = v.term_id AND curve_id = v.curve_id AND shares > 0) as actual_count
FROM vault v
WHERE v.position_count != (SELECT COUNT(*) ...);  -- Should return 0 rows
```

### 4. Regression Testing

**Query Performance:**
- Run existing analytics queries against new tables
- Compare execution times vs old materialized views
- Verify query plans use appropriate indexes

**Sample Queries to Test:**
```sql
-- Top vaults by market cap
SELECT * FROM vault ORDER BY market_cap DESC LIMIT 10;

-- User positions
SELECT * FROM position WHERE receiver = '0x...' AND shares > 0;

-- Triple analytics
SELECT * FROM predicate_object ORDER BY total_market_cap DESC LIMIT 10;
```

---

## Rollback Plan

**If Issues Arise:**

1. **Stop Rindexer:**
   ```bash
   # Stop indexing to prevent more events
   docker stop rindexer-container
   ```

2. **Restore Materialized Views:**
   ```bash
   # Re-run old migrations
   PGPASSWORD=rindexer psql ... -f migrations/02-position.sql.backup
   PGPASSWORD=rindexer psql ... -f migrations/03-vault.sql.backup
   # ... restore all old migration files
   ```

3. **Drop Trigger-Based Tables:**
   ```sql
   DROP TABLE IF EXISTS atom CASCADE;
   DROP TABLE IF EXISTS triple CASCADE;
   DROP TABLE IF EXISTS position CASCADE;
   -- ... drop all new tables
   ```

4. **Manual Refresh:**
   ```sql
   SELECT refresh_all_views();
   ```

**Recommendation:** Back up old migration files before replacing them.

---

## Implementation Checklist

### Phase 1: Preparation
- [ ] Review and understand existing materialized views
- [ ] Back up existing migration files (02-09, 99)
- [ ] Document all existing indexes and constraints

### Phase 2: Create New Migrations
- [ ] Write `02-tables.sql` with all 9 table definitions
- [ ] Write `03-trigger-functions.sql` with all trigger logic
- [ ] Add tracking columns (last_updated_block, last_updated_log_index)
- [ ] Create all necessary indexes

### Phase 3: Level 0 Implementation
- [ ] Implement `atom` table + trigger (simple)
- [ ] Implement `triple` table + trigger (moderate)
- [ ] Implement `position` table + triggers (complex)
- [ ] Test Level 0 with synthetic data

### Phase 4: Level 1 Implementation
- [ ] Implement `vault` table + triggers (complex)
- [ ] Implement `triple_vault` table + triggers (complex)
- [ ] Test Level 1 cascades

### Phase 5: Level 2 Implementation
- [ ] Implement `term` table + trigger (moderate)
- [ ] Implement `triple_term` table + trigger (moderate)
- [ ] Test Level 2 cascades

### Phase 6: Level 3 Implementation
- [ ] Implement `predicate_object` table + triggers (moderate)
- [ ] Implement `subject_predicate` table + triggers (moderate)
- [ ] Test full cascade from raw events to analytics

### Phase 7: Integration Testing
- [ ] Test out-of-order event handling
- [ ] Test idempotency (duplicate events)
- [ ] Performance benchmarking
- [ ] Data integrity validation

### Phase 8: Deployment
- [ ] Replace old migration files with new ones
- [ ] Update CLAUDE.md documentation
- [ ] Run fresh database setup from scratch
- [ ] Start rindexer and monitor initial indexing

---

## Expected Outcomes

### Benefits
✓ **Real-time updates** - Data available immediately as events arrive
✓ **No manual operations** - No need to call refresh functions
✓ **Simplified maintenance** - No dependency order management
✓ **Feature parity** - All current view logic preserved
✓ **Database-only** - No rindexer or application changes required

### Trade-offs
⚠ **Trigger overhead** - Each event may cascade through multiple tables
⚠ **Lock contention** - High-frequency updates to popular vaults
⚠ **Complexity** - More code to maintain (trigger functions vs simple views)
⚠ **Debugging** - Trigger execution is less visible than explicit refresh

### Success Metrics
- [ ] All tables update in real-time as events arrive
- [ ] No manual intervention required after initial setup
- [ ] Query performance matches or exceeds materialized views
- [ ] Out-of-order events handled correctly
- [ ] No data integrity issues under load

---

## Next Steps

1. **Review this plan** - Validate approach and assumptions
2. **Implement Phase 1-2** - Create new table definitions and trigger skeleton
3. **Implement Phase 3** - Build and test Level 0 triggers (atom, triple, position)
4. **Iterate through phases** - Complete remaining levels
5. **Test and validate** - Run comprehensive testing suite
6. **Deploy** - Replace old migrations and run from scratch

---

## Questions & Considerations

### Open Questions
- Should we add additional monitoring (e.g., trigger execution times in logs)?
- Do we need a "trigger disable" mechanism for bulk operations?
- Should we implement statement-level triggers for batch efficiency?

### Future Enhancements
- Consider partial indexes on tracking columns for better performance
- Add trigger execution metrics (execution_time, rows_affected)
- Implement trigger version tracking for future migrations
- Add admin function to manually recalculate aggregations if needed

---

*End of Plan*